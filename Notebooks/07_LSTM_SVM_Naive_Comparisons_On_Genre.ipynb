{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0786419ccb594a90bcae756c2aa4d07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c3ee885d6ad405ab92544236878edb9",
              "IPY_MODEL_5f65106587ea4d069159a21c52235f0a",
              "IPY_MODEL_8c6854c0b7754fd6b3e05b3c91c45a1d"
            ],
            "layout": "IPY_MODEL_3a4dc6d674df495e80b71395eeeed7e0"
          }
        },
        "2c3ee885d6ad405ab92544236878edb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_584088afe51b40a1b436b89ee10e3fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_5db615044b7f4b47b216bb5f57772567",
            "value": "Pandas Apply: 100%"
          }
        },
        "5f65106587ea4d069159a21c52235f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd7a4e87f6ef4f1081f978f043b1ea04",
            "max": 373300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdc39e07b521419a83780660e19c63c1",
            "value": 373300
          }
        },
        "8c6854c0b7754fd6b3e05b3c91c45a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_289486e5d69843949eee52c6683ce0c9",
            "placeholder": "​",
            "style": "IPY_MODEL_981a9ca2947049c7aae4de973bdacaa7",
            "value": " 373300/373300 [03:52&lt;00:00, 2459.09it/s]"
          }
        },
        "3a4dc6d674df495e80b71395eeeed7e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "584088afe51b40a1b436b89ee10e3fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5db615044b7f4b47b216bb5f57772567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7a4e87f6ef4f1081f978f043b1ea04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc39e07b521419a83780660e19c63c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "289486e5d69843949eee52c6683ce0c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "981a9ca2947049c7aae4de973bdacaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdc9f86361b5453986d56ef2e487f56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfe1908c471c442f8030c9eaffa39afb",
              "IPY_MODEL_4a44bfd2d8ff426aa5c8745189e51367",
              "IPY_MODEL_4538f33602ec48df8e37df4d8b4ab679"
            ],
            "layout": "IPY_MODEL_68ff1ed4d49949e0a7d0486d15c4bac1"
          }
        },
        "cfe1908c471c442f8030c9eaffa39afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_153e645887aa4efdaf80f38825202c3e",
            "placeholder": "​",
            "style": "IPY_MODEL_35db7a44fff9416e9ed8ff37d814e038",
            "value": "Pandas Apply: 100%"
          }
        },
        "4a44bfd2d8ff426aa5c8745189e51367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810564b7fa58470bb5fb4c8a415265eb",
            "max": 373300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6ae97aff00241719720493da7ae2a6b",
            "value": 373300
          }
        },
        "4538f33602ec48df8e37df4d8b4ab679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86e8f14accc4319b6c67eb316cd9d27",
            "placeholder": "​",
            "style": "IPY_MODEL_30fc3fa87be8420ba1714d8821744f58",
            "value": " 373300/373300 [59:02&lt;00:00, 125.61it/s]"
          }
        },
        "68ff1ed4d49949e0a7d0486d15c4bac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "153e645887aa4efdaf80f38825202c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35db7a44fff9416e9ed8ff37d814e038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "810564b7fa58470bb5fb4c8a415265eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ae97aff00241719720493da7ae2a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d86e8f14accc4319b6c67eb316cd9d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30fc3fa87be8420ba1714d8821744f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the Dataset** "
      ],
      "metadata": {
        "id": "OJwytXVqHUD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "file_name = 'Dataset_TXA.zip'\n",
        "\n",
        "# copying the dataset to the temporary workspace\n",
        "print('Copying Dataset to temporary workspace...')\n",
        "shutil.copyfile('drive/MyDrive/Dataset_TXA.zip', 'Dataset_TXA.zip')\n",
        "print('Copied...')\n",
        "\n",
        "# unzipping the dataset\n",
        "path = 'Dataset'\n",
        "with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "\n",
        "#moving inside the Dataset folder\n",
        "os.chdir(path)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Vm-frTGYHe1v",
        "outputId": "31b8956a-ce7f-4ebf-e117-15d9860d4ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Copying Dataset to temporary workspace...\n",
            "Copied...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gcFdDpCKLiJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d2bfe9-8dae-4234-abdc-b00fc3774397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Number of Rows: 12000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/training_set.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/test_df.csv')\n",
        "\n",
        "print(f'Number of Rows: {len(train_df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries and Preprocessing** "
      ],
      "metadata": {
        "id": "jWq-fJeGH3Q8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbC1Fu4tLlFR"
      },
      "outputs": [],
      "source": [
        "genres_corresp = (((\"Romance\", \"Erotica\", \"Polyamorous\", \"Category Romance\"), #-->\n",
        "                   (\"Romance\")),\n",
        "                  ((\"Fiction\", \"Young Adult\", \"New Adult\", \"Womens Fiction\", \"Adult Fiction\", \n",
        "                    \"Christian Fiction\", \"Realistic Fiction\", \"Fan Fiction\", \"Magical Realism\",\n",
        "                    \"Fantasy\", \"Superheroes\", \"Shapeshifters\", \"Science Fiction Fantasy\"), #-->\n",
        "                   (\"Fiction\")),\n",
        "                  ((\"Sequential Art\", \"Music\", \"Couture\"), #-->\n",
        "                   (\"Art\")),\n",
        "                  ((\"Thriller\", \"Mystery\", \"Crime\", \"Horror\", \"Paranormal\", \"Dark\", \"Suspense\"), #-->\n",
        "                   (\"Mystery\")),\n",
        "                  ((\"Science Fiction\", ), #just add a single comma to not loop in the string -->\n",
        "                   (\"Science Fiction\")),\n",
        "                  ((\"Classics\", \"Contemporary\", \"Poetry\", \"Plays\", \"Nonfiction\", \"Autobiography\", \n",
        "                    \"Biography\", \"Historical\", \"History\", \"War\", \"Mythology\"), #-->\n",
        "                   (\"NonFiction\")))\n",
        "\n",
        "genres_to_keep_dict = {k : v for ks, v in genres_corresp for k in ks}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "apF2aw7nLo5w",
        "outputId": "2707c4f0-b5ef-4959-c6ed-e503fbdca2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set up complete\n"
          ]
        }
      ],
      "source": [
        "!pip install swifter\n",
        "!pip install gensim\n",
        "!pip install transformers\n",
        "!pip install spacy\n",
        "!pip install umap-learn\n",
        "!pip install top2vec\n",
        "!pip install top2vec[sentence_encoders]\n",
        "!pip install tensorflow tensorflow_hub tensorflow_text\n",
        "!pip install top2vec[sentence_transformers]\n",
        "\n",
        "# to remove the output of the installation\n",
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)\n",
        "print('Set up complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIK17MxFLo8Q",
        "outputId": "b4d583b0-3243-4e65-bbe0-cb3c47c0743b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import swifter\n",
        "import umap\n",
        "import keras\n",
        "\n",
        "default_params = mpl.rcParamsDefault\n",
        "\n",
        "import re\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Pos tagging correspondence\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Stop words\n",
        "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
        "# Compute bigrams.\n",
        "from gensim.models import Phrases\n",
        "# Utility to compute dictionary\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Ner visualization\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "import torch\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Lemmatize the documents.\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "# Vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Classification\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import  svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "stop_words = set(STOPWORDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M1aLbaW3RxkQ"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from top2vec import Top2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning different patterns\n",
        "def clean_tokens(tokens):\n",
        "    \"\"\"\n",
        "    It cleans the tokens from unrelevant characters\n",
        "    \"\"\"\n",
        "    tokens = re.sub(r\"http[s]*\\S+\", \"\", tokens) #removing urls\n",
        "    tokens = re.sub(r\"[^\\w\\s'!.,]\", '', tokens)\n",
        "    tokens = re.sub('\\d\\s*star[s]?', '', tokens) # removing ratings from reviews\n",
        "    tokens = re.sub(r'<.*?>', '', tokens) #removing HTMLS\n",
        "    tokens = re.sub(r\"\\\\\", \"\", tokens) #removing \\ character\n",
        "    tokens = re.sub(r\"\\n\", \"\", tokens) #removing new line characters\n",
        "    tokens = re.sub(r'\\b\\d+\\b', '', tokens) #removing numbers\n",
        "    tokens = re.sub(r'spoiler[s]?', '', tokens) #removing spoiler alert\n",
        "    tokens = re.sub('\\S*\\d+\\S*', '', tokens) # removing words with still numbers inside\n",
        "    tokens = re.sub(\"(.)\\1{2,}\", r\"\\1\", tokens) #removing extra characters\n",
        "    tokens = re.sub(\"[.,'!]\\s(\\b)\", r\"\\1\", tokens) #removing punctuation that was left without words\n",
        "    tokens = re.sub(\"^[.,]\\s\", '', tokens) #removing punctuation at the start of the line if present\n",
        "    tokens = re.sub(\"[.,]\\s?$\", '', tokens) #removing punctuation at the end of the line if present\n",
        "    tokens = re.sub(r'([.,])(\\S)', r'\\1 \\2', tokens) # adding a space after punctuation\n",
        "    tokens = re.sub(\"(\\s){1,}\", r\"\\1\", tokens) #removing extra spaces\n",
        "    token = re.sub(r\"\\s([.,!])\", r\"\\1\", tokens) # removing spaces before punctuation\n",
        "    token = re.sub(r\"([.,]){1,}\", r\"\\1\", tokens) # removing extra commas and dots\n",
        "    token = re.sub(r\"\\s('[mst])\", r\"\\1\", tokens) # removing spaces before the apostrophe\n",
        "    \n",
        "    return tokens.strip().lower()"
      ],
      "metadata": {
        "id": "mjJyL1JCmwU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning stopwords and words containing non alphanumeric characters\n",
        "def remove_stop_words(column, pos = False):\n",
        "    \"\"\"\n",
        "    It removes the stop words from a column or an iterable of tokens, \n",
        "    the pos parameter specify if the pos is present in the iterable.\n",
        "    e.g. pos == True iff [(holy, JJ), (crap, NN), (awesome, NN) <-- [0] word, [1] pos\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if pos == False:\n",
        "        return [[token for token in review_text if (token not in stop_words) and token.isalpha()] for review_text in column]\n",
        "    else: #token[0] because it is assumed the token is the first position of the tuple\n",
        "        return [[token for token in review_text if (token[0] not in stop_words) and token[0].isalpha()] for review_text in column]"
      ],
      "metadata": {
        "id": "s0skY_CAm1je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"\n",
        "    To interpret the postag to wordnet lexicon\n",
        "    \"\"\"\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "isv6dLYam5Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_row(row):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_row = list()\n",
        "    \n",
        "    for token, pos in row:\n",
        "        if pos is None:\n",
        "            lemma = lemmatizer.lemmatize(token)\n",
        "        else:\n",
        "            lemma = lemmatizer.lemmatize(token, pos = pos)\n",
        "\n",
        "        lemmatized_row.append(lemma)\n",
        "\n",
        "    return lemmatized_row"
      ],
      "metadata": {
        "id": "WSZU6d4NNegc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatization(clean_review):\n",
        "    tokenized_review = word_tokenize(clean_review)\n",
        "    postagged_review = nltk.pos_tag(tokenized_review)\n",
        "    postagged_review_for_lemma = [(tup[0], get_wordnet_pos(tup[1])) if len(tup) == 2 else tup for tup in postagged_review]\n",
        "    lemmatized_review = lemmatize_row([tup for tup in postagged_review_for_lemma if len(tup[0]) > 2])\n",
        "    return lemmatized_review"
      ],
      "metadata": {
        "id": "rExYDVOobzpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading and preprocessing the test set\n",
        "test_df = pd.read_csv('gr_test_set.csv', usecols=['review_text', 'genre', 'book_id']).dropna().reset_index(drop=True)\n",
        "test_df = test_df[test_df.genre.isin(genres_to_keep_dict.keys())].reset_index(drop=True)\n",
        "test_df.genre = test_df.genre.map(lambda genere: genres_to_keep_dict[genere])\n",
        "test_df['review_text'] = test_df.review_text.swifter.apply(lambda x: clean_tokens(x))\n",
        "\n",
        "print(f'Number of Rows: {len(test_df)}')\n",
        "     "
      ],
      "metadata": {
        "id": "LpFXbhVem8-A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0786419ccb594a90bcae756c2aa4d07c",
            "2c3ee885d6ad405ab92544236878edb9",
            "5f65106587ea4d069159a21c52235f0a",
            "8c6854c0b7754fd6b3e05b3c91c45a1d",
            "3a4dc6d674df495e80b71395eeeed7e0",
            "584088afe51b40a1b436b89ee10e3fa5",
            "5db615044b7f4b47b216bb5f57772567",
            "bd7a4e87f6ef4f1081f978f043b1ea04",
            "cdc39e07b521419a83780660e19c63c1",
            "289486e5d69843949eee52c6683ce0c9",
            "981a9ca2947049c7aae4de973bdacaa7"
          ]
        },
        "outputId": "9b28b485-7fb2-49bb-d539-ea94930a92c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pandas Apply:   0%|          | 0/373300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0786419ccb594a90bcae756c2aa4d07c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows: 373300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['lemmatized_text'] = test_df.review_text.swifter.apply(lambda x: lemmatization(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fdc9f86361b5453986d56ef2e487f56e",
            "cfe1908c471c442f8030c9eaffa39afb",
            "4a44bfd2d8ff426aa5c8745189e51367",
            "4538f33602ec48df8e37df4d8b4ab679",
            "68ff1ed4d49949e0a7d0486d15c4bac1",
            "153e645887aa4efdaf80f38825202c3e",
            "35db7a44fff9416e9ed8ff37d814e038",
            "810564b7fa58470bb5fb4c8a415265eb",
            "e6ae97aff00241719720493da7ae2a6b",
            "d86e8f14accc4319b6c67eb316cd9d27",
            "30fc3fa87be8420ba1714d8821744f58"
          ]
        },
        "id": "ydsDD9q3cjzq",
        "outputId": "8c9e5880-5513-4826-e181-787cd5b163ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pandas Apply:   0%|          | 0/373300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdc9f86361b5453986d56ef2e487f56e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "38l2YoCtN3XU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9e1e4b69-7fac-4b78-fbbb-ce6935e7cf3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_text genre  rating   book_id  \\\n",
              "0  breezy hijinks, fun to read. think i finished ...   Art       3  22718721   \n",
              "1  for the story, for the artwork. you know how t...   Art       2  13533744   \n",
              "2  rat queens so the rat queens are to fight the ...   Art       3  23012877   \n",
              "3  i knew nothing about eternals before reading t...   Art       2     47694   \n",
              "4  better than the last book, this one moves the ...   Art       3  12137592   \n",
              "\n",
              "                                     lemmatized_text  \\\n",
              "0  ['breezy', 'hijinks', 'fun', 'read', 'think', ...   \n",
              "1  ['story', 'artwork', 'know', 'best', 'best', '...   \n",
              "2  ['rat', 'queen', 'rat', 'queen', 'fight', 'man...   \n",
              "3  ['know', 'eternals', 'read', 'pretty', 'get', ...   \n",
              "4  ['good', 'book', 'move', 'plot', 'forward', 'n...   \n",
              "\n",
              "                                   lemmatized_joined  \n",
              "0  breezy hijinks fun read think finish sitting a...  \n",
              "1  story artwork know best best come later rejuve...  \n",
              "2  rat queen rat queen fight man kidnap bernardet...  \n",
              "3  know eternals read pretty get neil gaiman know...  \n",
              "4  good book move plot forward ntroduces dead pre...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bb7d6d0-d4c1-4e3a-9577-dfb095e803dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>genre</th>\n",
              "      <th>rating</th>\n",
              "      <th>book_id</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>lemmatized_joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breezy hijinks, fun to read. think i finished ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>22718721</td>\n",
              "      <td>['breezy', 'hijinks', 'fun', 'read', 'think', ...</td>\n",
              "      <td>breezy hijinks fun read think finish sitting a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>for the story, for the artwork. you know how t...</td>\n",
              "      <td>Art</td>\n",
              "      <td>2</td>\n",
              "      <td>13533744</td>\n",
              "      <td>['story', 'artwork', 'know', 'best', 'best', '...</td>\n",
              "      <td>story artwork know best best come later rejuve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rat queens so the rat queens are to fight the ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>23012877</td>\n",
              "      <td>['rat', 'queen', 'rat', 'queen', 'fight', 'man...</td>\n",
              "      <td>rat queen rat queen fight man kidnap bernardet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i knew nothing about eternals before reading t...</td>\n",
              "      <td>Art</td>\n",
              "      <td>2</td>\n",
              "      <td>47694</td>\n",
              "      <td>['know', 'eternals', 'read', 'pretty', 'get', ...</td>\n",
              "      <td>know eternals read pretty get neil gaiman know...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>better than the last book, this one moves the ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>12137592</td>\n",
              "      <td>['good', 'book', 'move', 'plot', 'forward', 'n...</td>\n",
              "      <td>good book move plot forward ntroduces dead pre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bb7d6d0-d4c1-4e3a-9577-dfb095e803dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bb7d6d0-d4c1-4e3a-9577-dfb095e803dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bb7d6d0-d4c1-4e3a-9577-dfb095e803dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import ast\n",
        "train_df['lemmatized_joined'] = train_df['lemmatized_text'].transform(lambda x: ' '.join(ast.literal_eval(x)))\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['lemmatized_joined'] = test_df['lemmatized_text'].transform(lambda x: ' '.join(ast.literal_eval(x)))\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "UPJnIaFWZPnP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6a8c4cfa-43fd-4cb5-cef4-6077aec37754"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    book_id                                        review_text    genre  \\\n",
              "0   7092507  alert this is definitely one of my favorites a...  Fiction   \n",
              "1   5576654  alert you are what you drink. i'm a huge fan o...  Fiction   \n",
              "2  15754052  roar is one of my favorite characters in under...  Fiction   \n",
              "3     17020  alert if you feel like travelling to europe an...  Fiction   \n",
              "4  12551082  i read and enjoyed the first two novels from t...  Fiction   \n",
              "\n",
              "                                     lemmatized_text  \\\n",
              "0  ['alert', 'this', 'definitely', 'one', 'favori...   \n",
              "1  ['alert', 'you', 'be', 'what', 'you', 'drink',...   \n",
              "2  ['roar', 'one', 'favorite', 'character', 'unde...   \n",
              "3  ['alert', 'you', 'feel', 'like', 'travel', 'eu...   \n",
              "4  ['read', 'and', 'enjoy', 'the', 'first', 'two'...   \n",
              "\n",
              "                                   lemmatized_joined  \n",
              "0  alert this definitely one favorite among the f...  \n",
              "1  alert you be what you drink huge fan coffee bu...  \n",
              "2  roar one favorite character under the never sk...  \n",
              "3  alert you feel like travel europe and you n't ...  \n",
              "4  read and enjoy the first two novel from this s...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41a0d67a-0fbe-4183-9578-9f7eef67d255\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>genre</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>lemmatized_joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7092507</td>\n",
              "      <td>alert this is definitely one of my favorites a...</td>\n",
              "      <td>Fiction</td>\n",
              "      <td>['alert', 'this', 'definitely', 'one', 'favori...</td>\n",
              "      <td>alert this definitely one favorite among the f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5576654</td>\n",
              "      <td>alert you are what you drink. i'm a huge fan o...</td>\n",
              "      <td>Fiction</td>\n",
              "      <td>['alert', 'you', 'be', 'what', 'you', 'drink',...</td>\n",
              "      <td>alert you be what you drink huge fan coffee bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15754052</td>\n",
              "      <td>roar is one of my favorite characters in under...</td>\n",
              "      <td>Fiction</td>\n",
              "      <td>['roar', 'one', 'favorite', 'character', 'unde...</td>\n",
              "      <td>roar one favorite character under the never sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17020</td>\n",
              "      <td>alert if you feel like travelling to europe an...</td>\n",
              "      <td>Fiction</td>\n",
              "      <td>['alert', 'you', 'feel', 'like', 'travel', 'eu...</td>\n",
              "      <td>alert you feel like travel europe and you n't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12551082</td>\n",
              "      <td>i read and enjoyed the first two novels from t...</td>\n",
              "      <td>Fiction</td>\n",
              "      <td>['read', 'and', 'enjoy', 'the', 'first', 'two'...</td>\n",
              "      <td>read and enjoy the first two novel from this s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41a0d67a-0fbe-4183-9578-9f7eef67d255')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41a0d67a-0fbe-4183-9578-9f7eef67d255 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41a0d67a-0fbe-4183-9578-9f7eef67d255');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.sample(frac=0.1)\n",
        "len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_ktuFtFF3l0",
        "outputId": "760099bf-16f8-4632-9cd5-e3fc1752deec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37330"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('test_df_sample.csv', index = False)"
      ],
      "metadata": {
        "id": "Jkf3V6SVQueJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Genre Classification: LSTM, SVM and Naive Bayes**"
      ],
      "metadata": {
        "id": "IRvR8dG3557I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we'll try different embeddings and strategies to get interesting results. We will proceed this way due to the fact that, for the 'genre' classification task, we found it difficult to get good performance for the validation set. Trying to overcome this problem, in this section we will try, both for LSTM, SVM and Naive Bayes:\n",
        "\n",
        "\n",
        "\n",
        "*   **Tokenizer** (provided from Keras, in general used for deep neural networks)\n",
        "*   **CountVectorizer** \n",
        "*   **CountVectorizer with Umap Reduction**\n",
        "*   **Tf-idf** \n",
        "*   **Tf-idf with Umap Reduction**\n",
        "*   **Top2Vec** creating a new filtered column based on words similar to the different genre classes\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MDW_VgOD590D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_df['lemmatized_joined']\n",
        "test = test_df['lemmatized_joined']\n",
        "y = train_df['genre']\n",
        "# encoding labels\n",
        "Y = pd.get_dummies(y)"
      ],
      "metadata": {
        "id": "tIqVszB57zvC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenizer**"
      ],
      "metadata": {
        "id": "pAoH-TQa7Hs3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg4jkOyevmoI"
      },
      "outputs": [],
      "source": [
        "def cust_tokenizer(num_words, col):\n",
        "  tokenizer = Tokenizer(num_words=num_words)\n",
        "  tokenizer.fit_on_texts(col)\n",
        "  X = tokenizer.texts_to_sequences(col)\n",
        "  word_index = tokenizer.word_index\n",
        "  # check the max len in order to use this value later (for parameter 'input_length' of the model and for pad_sequence)\n",
        "  maxim = max([len(x) for x in X])\n",
        "  return X, word_index, maxim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = cust_tokenizer(20000, train)\n",
        "print('There are {} unique tokens and the maximum sequence length is {}.'.format(len(X[1]), X[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvTEeeqQbnJJ",
        "outputId": "7ee3d0a1-d2f6-4081-c819-eeae109b6958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 43024 unique tokens and the maximum sequence length is 180.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for creating vector of same length\n",
        "Xp = pad_sequences(X[0], maxlen=X[2])"
      ],
      "metadata": {
        "id": "sRO2F5Qz8y2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The maximum number of words to be used, i.e. the the most frequent.\n",
        "max_nwords = 20000\n",
        "# Maximum number of words in each complaint.\n",
        "max_seq_len = 180\n",
        "# Fixed value\n",
        "embedd_dim = 60"
      ],
      "metadata": {
        "id": "5iNhof399Ya5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_nwords, embedd_dim, input_length=max_seq_len))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2, activation = 'softmax', return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(128)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGak9DWF94BR",
        "outputId": "4c2e5fee-46de-4802-ec3b-d383622fee66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 180, 60)           1200000   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 180, 256)         193536    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 180, 256)          0         \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 256)              394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 18)                4626      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 18)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 114       \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,792,516\n",
            "Trainable params: 1,792,516\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After testing different models with different layers and different optimizers, we chose a learning rate of 0.001 to keep the loss lower (although the loss is always similar in the other cases)."
      ],
      "metadata": {
        "id": "TayvxqKyJfMg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1KuKiNnSWpt",
        "outputId": "6575253c-e484-4397-aa2a-203975bd3138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "66/66 [==============================] - 152s 2s/step - loss: 0.8513 - accuracy: 0.2373 - val_loss: 0.5234 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/6\n",
            "66/66 [==============================] - 135s 2s/step - loss: 0.8656 - accuracy: 0.2385 - val_loss: 0.5497 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/6\n",
            "66/66 [==============================] - 115s 2s/step - loss: 0.8590 - accuracy: 0.2321 - val_loss: 0.5727 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/6\n",
            "66/66 [==============================] - 115s 2s/step - loss: 0.8614 - accuracy: 0.2350 - val_loss: 0.5971 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/6\n",
            "66/66 [==============================] - 112s 2s/step - loss: 0.8461 - accuracy: 0.2382 - val_loss: 0.6228 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "epochs = 6\n",
        "batch_size = 128\n",
        "history = model.fit(Xp, Y, epochs=epochs, batch_size=batch_size,validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss', patience=4, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding label for svm\n",
        "Encoder = LabelEncoder()\n",
        "Yt = Encoder.fit_transform(train_df['genre'])\n",
        "Ytest = Encoder.fit_transform(test_df['genre'])"
      ],
      "metadata": {
        "id": "_esV-RFKelrH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For computational reasons, we reduce the value of the num_words parameter of Tokenizer to 5000 only for SVM (with 20000 words it takes a lot of time)."
      ],
      "metadata": {
        "id": "1A3f_cuEw1v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = cust_tokenizer(5000, train)\n",
        "Xp = pad_sequences(X[0])"
      ],
      "metadata": {
        "id": "doGBWvYOtmK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(Xp,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "jWrDtu5xL3nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='rbf', degree=6, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))"
      ],
      "metadata": {
        "id": "95RAQB-08FPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8f6cb2-1c8c-4ae0-c179-07f2c7e6cd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(degree=6, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score --->  15.833333333333332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see performance on validation \n",
        "model_naive = MultinomialNB(alpha=0.2)\n",
        "model_naive.fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WonAaTfSf67F",
        "outputId": "aee45f5d-db39-4627-e8f0-90055dfe4a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_naive.predict(Xtrain)\n",
        "y_pred = model_naive.predict(Xval)\n",
        "# comparing real values with predicted values  \n",
        "print(\"Train accuracy(in %): {}\".format(metrics.accuracy_score(Ytrain, y_train_pred)*100))\n",
        "print(\"Validation accuracy(in %): {}\".format(metrics.accuracy_score(Yval, y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoKC89hegBg8",
        "outputId": "4de48f60-6c36-4655-fb7b-53493220c259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy(in %): 20.42857142857143\n",
            "Validation accuracy(in %): 16.86111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, since the Tokenizer is a technique used especially for deep neural networks, we have bad performance and even using 20000 or 5000 words for the Tokenizer, the performance does not improve."
      ],
      "metadata": {
        "id": "Snz62pH0zVWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CountVectorizer**"
      ],
      "metadata": {
        "id": "izS6Ps5mHR-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilTxIo5yjNjR"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(min_df=2, max_features=20000)\n",
        "word_doc_matrix = vectorizer.fit_transform(train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for padding we have to reduce dimensionality of the matrix\n",
        "from sklearn.decomposition import TruncatedSVD        \n",
        "pca = TruncatedSVD(n_components=6)                                \n",
        "X_reduced_train = pca.fit_transform(word_doc_matrix)  "
      ],
      "metadata": {
        "id": "uNAf8B7FLrUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xp = pad_sequences(X_reduced_train)\n",
        "Xp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-U8ZEQuKO5q",
        "outputId": "5436828e-e563-418a-e960-714955b9b0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nowo7CpaZXLw"
      },
      "outputs": [],
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "max_nwords = 20000\n",
        "# Max number of words in each complaint.\n",
        "max_seq_length = 6\n",
        "embedding_dim = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE3dg1UMjNtO",
        "outputId": "cd706e93-1837-4dd3-f6cf-e73e47e3890f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 6, 6)              120000    \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 200)              85600     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 6)                 1206      \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 206,806\n",
            "Trainable params: 206,806\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_nwords, embedding_dim, input_length=max_seq_length))\n",
        "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2, activation = 'sigmoid')))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1xSXUsAZsYM",
        "outputId": "4f220968-1542-46d7-f820-776fec9a64ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "66/66 [==============================] - 10s 70ms/step - loss: 0.8292 - accuracy: 0.2438 - val_loss: 0.8871 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.8163 - accuracy: 0.2468 - val_loss: 0.9134 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.8282 - accuracy: 0.2576 - val_loss: 0.9364 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.8278 - accuracy: 0.2801 - val_loss: 0.9685 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.8454 - accuracy: 0.2815 - val_loss: 0.9770 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "batch_size = 128\n",
        "history = model.fit(Xp, Y, epochs=epochs, batch_size=batch_size,validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(word_doc_matrix,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "yi333R-lgkIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import  svm\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=6, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc844c8-c13b-4ade-b765-a2e23e835a5f",
        "id": "KOezkueigkIw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, degree=6, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 105
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score ---> 31.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see performance on validation \n",
        "model_naive = MultinomialNB(alpha=0.2)\n",
        "model_naive.fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0235901b-9a7b-449b-c347-a33c867b86f7",
        "id": "GsD1KOSJgkIx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_naive.predict(Xtrain)\n",
        "y_pred = model_naive.predict(Xval)\n",
        "# comparing real values with predicted values  \n",
        "print(\"Train accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Ytrain, y_train_pred)*100))\n",
        "print(\"Validation accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Yval, y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce503b0-4e2a-4406-dd94-94c9594ecd8c",
        "id": "PBMHYp82gkIx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy for Naive Bayes (in %): 94.48809523809524\n",
            "Validation accuracy for Naive Bayes (in %): 72.97222222222223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, a *higher value of num_words for CountVectorizer improves the performance only for Naive Bayes* (with 20000 we have good scores, but if we lower the num_words value the perfomance decreases), instead maintaining a *lower performance for LSTM* and an *increase for SVM score* compared to the previous case."
      ],
      "metadata": {
        "id": "3UsM97lI0K9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CountVectorizer + Umap reduction**"
      ],
      "metadata": {
        "id": "ATm7uIwTOoql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Preprocessing section we have seen a Umap plot in which the classes appears well divided. So here we will see if there are any differences in the scores using a *Umap reduction*. "
      ],
      "metadata": {
        "id": "C1oB7hwg0y3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will try to use the default value of Umap function of **n_component (=2)**, then we will try to increase this value. "
      ],
      "metadata": {
        "id": "2UohQM7A89Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def umap_reduction(matrix, component=False):\n",
        "  reducer = umap.UMAP().fit(matrix) if component == False else umap.UMAP(n_components=component).fit(matrix)\n",
        "  embedding = reducer.fit_transform(matrix)\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "DaYIioOj6iTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = umap_reduction(word_doc_matrix)"
      ],
      "metadata": {
        "id": "LpuIwFa97m4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(embedding)\n",
        "# The maximum number of words to be used. (most frequent)\n",
        "max_nwords = 20000\n",
        "# Max number of words in each complaint.\n",
        "max_seq_length = 2\n",
        "embedding_dim = 2"
      ],
      "metadata": {
        "id": "9LOE-3pEPSvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6484db38-7c6c-48d3-a933-3a44272abfa1",
        "id": "0xw33WJpQGUt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 2, 2)              40000     \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirecti  (None, 256)              134144    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 175,686\n",
            "Trainable params: 175,686\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_nwords, embedding_dim, input_length=max_seq_length))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2, activation = 'sigmoid')))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e9f7a5-7739-4055-e7bc-f3de124eb72c",
        "id": "978-i9T9Pc9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "132/132 [==============================] - 9s 33ms/step - loss: 0.8356 - accuracy: 0.2382 - val_loss: 0.9137 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 0.8368 - accuracy: 0.2676 - val_loss: 0.9802 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "132/132 [==============================] - 4s 27ms/step - loss: 0.8297 - accuracy: 0.3120 - val_loss: 0.9993 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "132/132 [==============================] - 3s 26ms/step - loss: 0.8258 - accuracy: 0.3243 - val_loss: 1.0222 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "history = model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(embedding,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "h9h0_6z4k7G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import  svm\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ARSbXtk7G5",
        "outputId": "1f6935f7-6691-4dc4-f159-7853a8fec9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score --->  32.361111111111114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For running Naive Bayes, we use the padding version because the Umap reduction also gives negative values which are not accepted by the Naive classifier (and we get a lower score for that)."
      ],
      "metadata": {
        "id": "DdqG7Rmy-Er5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(X,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "pdsaxTqJ9rd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see performance on validation \n",
        "model_naive = MultinomialNB(alpha=0.2)\n",
        "model_naive.fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6cb121-914e-4815-e1d9-2a9cc8d2b1b5",
        "id": "vd87l7auk7G5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_naive.predict(Xtrain)\n",
        "y_pred = model_naive.predict(Xval)\n",
        "  \n",
        "# comparing real values with predicted values  \n",
        "print(\"Train accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Ytrain, y_train_pred)*100))\n",
        "print(\"Validation accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Yval, y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ae54ef-4b88-4efa-fd88-ef0a44d2b21e",
        "id": "O8xw6-R_k7G5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy for Naive Bayes (in %): 22.952380952380953\n",
            "Validation accuracy for Naive Bayes (in %): 22.805555555555557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, with CountVectorizer + Umap we have seen a decrease in the performance of Naive Bayes. SVM maintained the same accuracy and the LSTM score increased slightly."
      ],
      "metadata": {
        "id": "DmRvsm3r2FeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see with **6 components** if there are differences from the default 2 components:"
      ],
      "metadata": {
        "id": "HQ5r_-8ABASM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# take the matrix defined above woth CountVectorizer\n",
        "embedding = umap_reduction(word_doc_matrix, 6)"
      ],
      "metadata": {
        "id": "6gwPjMrRA_Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(embedding)\n",
        "max_nwords = 20000\n",
        "max_seq_length = 6\n",
        "embedding_dim = 5"
      ],
      "metadata": {
        "id": "9fMNNKk_Bwlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c6aec2-ab27-415b-f841-28b1fd6b28c4",
        "id": "-4DA_VhGBwlq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_17 (Embedding)    (None, 6, 5)              100000    \n",
            "                                                                 \n",
            " bidirectional_21 (Bidirecti  (None, 256)              137216    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 238,758\n",
            "Trainable params: 238,758\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_nwords, embedding_dim, input_length=max_seq_length))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2, activation = 'sigmoid')))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f30d653-323b-4b54-bb32-efb4e3e47511",
        "id": "dUDtfV-VBwlr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "132/132 [==============================] - 14s 70ms/step - loss: 0.8477 - accuracy: 0.2533 - val_loss: 0.9787 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "132/132 [==============================] - 11s 82ms/step - loss: 0.8218 - accuracy: 0.3232 - val_loss: 1.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "132/132 [==============================] - 9s 66ms/step - loss: 0.7998 - accuracy: 0.3708 - val_loss: 1.0374 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "132/132 [==============================] - 9s 66ms/step - loss: 0.7999 - accuracy: 0.4004 - val_loss: 1.0788 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "132/132 [==============================] - 9s 64ms/step - loss: 0.7942 - accuracy: 0.4185 - val_loss: 1.1236 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "132/132 [==============================] - 9s 65ms/step - loss: 0.8036 - accuracy: 0.4235 - val_loss: 1.1085 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "history = model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(embedding,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "GO5MKGuZBwlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import  svm\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2178bf96-3009-4a49-e762-382fc85a9ef2",
        "id": "M1sRy4f8Bwlr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 119
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score ---> 53.861111111111114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(X,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "8iTkDGBnBwls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see performance on validation \n",
        "model_naive = MultinomialNB(alpha=0.2)\n",
        "model_naive.fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81676b5a-7375-47a5-f263-1208b7a74e28",
        "id": "yOos2qX0Bwls"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_naive.predict(Xtrain)\n",
        "y_pred = model_naive.predict(Xval)\n",
        "  \n",
        "# comparing real values with predicted values  \n",
        "print(\"Train accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Ytrain, y_train_pred)*100))\n",
        "print(\"Validation accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Yval, y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e61dd8-aa24-4773-b0a3-9109f3210843",
        "id": "Lua8OBIZBwls"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy for Naive Bayes (in %): 31.19047619047619\n",
            "Validation accuracy for Naive Bayes (in %): 30.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using 6 components we have a greater perfomance for **LSTM (from 32% to 42%)** and in particular for **SVM (from 32% to 54%).**"
      ],
      "metadata": {
        "id": "B0AVBOK9EpHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tf-idf** "
      ],
      "metadata": {
        "id": "NqQQ4cV1Q9DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=20000)\n",
        "TrainTDF = Tfidf_vect.fit_transform(train)"
      ],
      "metadata": {
        "id": "z4ClpRT8QWuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need reduction for padding\n",
        "pca = TruncatedSVD(n_components=6)                                \n",
        "X_reduced_train = pca.fit_transform(TrainTDF)  "
      ],
      "metadata": {
        "id": "-gFqYOrrRSTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(X_reduced_train)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab4f6e4-c8c1-42dc-ed74-dc0283d80856",
        "id": "mWz3Q3cYRse1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c850a1-1591-4763-cb61-69b6bc3f13b1",
        "id": "DqVB-A7_SE2A"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_22 (Embedding)    (None, 6, 5)              100000    \n",
            "                                                                 \n",
            " bidirectional_26 (Bidirecti  (None, 256)              137216    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 238,758\n",
            "Trainable params: 238,758\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_nwords, embedding_dim, input_length=max_seq_length))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2, activation = 'softmax')))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20097180-fcd6-4232-c02d-9864acf464b9",
        "id": "mSPOhq-oR7EQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "66/66 [==============================] - 10s 77ms/step - loss: 0.8845 - accuracy: 0.2389 - val_loss: 0.4836 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "66/66 [==============================] - 5s 71ms/step - loss: 0.8619 - accuracy: 0.2335 - val_loss: 0.5163 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "66/66 [==============================] - 5s 69ms/step - loss: 0.8704 - accuracy: 0.2302 - val_loss: 0.5508 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "66/66 [==============================] - 5s 69ms/step - loss: 0.8541 - accuracy: 0.2423 - val_loss: 0.5886 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "66/66 [==============================] - 4s 67ms/step - loss: 0.8578 - accuracy: 0.2293 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "66/66 [==============================] - 4s 67ms/step - loss: 0.8529 - accuracy: 0.2304 - val_loss: 0.6548 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "batch_size = 128\n",
        "history = model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(TrainTDF,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "Nhwups5Uk8Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import  svm\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=6, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj5u9vIHk8Jf",
        "outputId": "5b15ade8-326b-499d-8317-d422158eb9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, degree=6, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 151
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score --->  15.666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see performance on validation \n",
        "model_naive = MultinomialNB(alpha=0.2)\n",
        "model_naive.fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a1e87e-d0f0-46f6-adae-c1714d4a934a",
        "id": "VF8BJNwfk8Jf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_naive.predict(Xtrain)\n",
        "y_pred = model_naive.predict(Xval)\n",
        "  \n",
        "# comparing real values with predicted values  \n",
        "print(\"Train accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Ytrain, y_train_pred)*100))\n",
        "print(\"Validation accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Yval, y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fdd3a8-1806-4c48-9378-115ea0522a2b",
        "id": "rAiIw5Jtk8Jg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy(in %): 95.73809523809523\n",
            "Validation accuracy(in %): 72.91666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf-idf values seems not so good for SVM as they are for Naive Bayes."
      ],
      "metadata": {
        "id": "ChTTK2tZ36pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But if we take the reduced version of Tf-idf (with 6 components) for the SVM model we get a higher score:"
      ],
      "metadata": {
        "id": "EMdLyM4nKzWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(X_reduced_train,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "k6Wg5wnXKirq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import  svm\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=6, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4f4fc9-8404-427a-a09e-1783a40f2aad",
        "id": "lopzH_QPKirq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, degree=6, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 155
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score --->  40.91666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tf-idf + Umap reduction**"
      ],
      "metadata": {
        "id": "263iIUGRS579"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use directly 6 components for Umap reduction:"
      ],
      "metadata": {
        "id": "jniSz7hxLuOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = umap_reduction(TrainTDF,6)"
      ],
      "metadata": {
        "id": "7YldRd84TBmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(embedding)\n",
        "max_nwords = 20000\n",
        "max_seq_length = 6\n",
        "embedding_dim = 5"
      ],
      "metadata": {
        "id": "Mf_l5g6OMprs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a001aea2-fc18-4e50-834c-137076567ac7",
        "id": "i7PISc_jTfB9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "66/66 [==============================] - 5s 72ms/step - loss: 0.8322 - accuracy: 0.2381 - val_loss: 0.6516 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "66/66 [==============================] - 5s 72ms/step - loss: 0.8372 - accuracy: 0.2374 - val_loss: 0.6791 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "66/66 [==============================] - 5s 71ms/step - loss: 0.8451 - accuracy: 0.2374 - val_loss: 0.7005 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "66/66 [==============================] - 5s 72ms/step - loss: 0.8389 - accuracy: 0.2401 - val_loss: 0.7180 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "batch_size = 128\n",
        "history = model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(embedding,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "6jODNtsfk9V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import  svm\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=6, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkDMGjiMk9V3",
        "outputId": "70be8d5b-0a53-4e14-8649-e3c10e910b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, degree=6, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 178
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score ---> 51.19444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even if we tried to change layers, optimizers and dropouts the validation accuracy remains *always low for LSTM (except for CounVectorizer+Umap(6 components)*. Overall, the **best perfomance** we got **for SVM are those in relation to UMAP reduction**, while **for Naive Bayes** we get **higher scores withouth UMAP reduction**."
      ],
      "metadata": {
        "id": "n9Dk2mdlScA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Top2Vec**"
      ],
      "metadata": {
        "id": "0w1p1oSB6im1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea comes again from the observation of the UMAP plot in the \"Preprocessing\" section where, by recognizing the different topics, it is possible to see a situation in which the different classes seem to be distinguishable."
      ],
      "metadata": {
        "id": "TvjavsBn8Ses"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Top2Vec helps us in finding topics in our corpus, in this section *we try to use Top2Vec to found words that are **semantically \"similar\" to some specified words (in our case, we use only the words of 'genre' classes**)*. Next, we create a new column that's a filtered version of the lemmatized_joined column with only the words that we've previously found similar to the genre classes. "
      ],
      "metadata": {
        "id": "cM-CQnUO7LGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this way, we will see if there are any difference for classification. "
      ],
      "metadata": {
        "id": "GpX_Bx2O8IAs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCEGrgPaqwe3",
        "outputId": "4ba68315-d425-4f17-ed84-e28156375a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-08 02:10:14,502 - top2vec - INFO - Pre-processing documents for training\n",
            "INFO:top2vec:Pre-processing documents for training\n",
            "2022-12-08 02:10:18,780 - top2vec - INFO - Downloading universal-sentence-encoder model\n",
            "INFO:top2vec:Downloading universal-sentence-encoder model\n",
            "2022-12-08 02:10:23,196 - top2vec - INFO - Creating joint document/word embedding\n",
            "INFO:top2vec:Creating joint document/word embedding\n",
            "2022-12-08 02:10:28,776 - top2vec - INFO - Creating lower dimension embedding of documents\n",
            "INFO:top2vec:Creating lower dimension embedding of documents\n",
            "2022-12-08 02:10:46,247 - top2vec - INFO - Finding dense areas of documents\n",
            "INFO:top2vec:Finding dense areas of documents\n",
            "2022-12-08 02:10:46,757 - top2vec - INFO - Finding topics\n",
            "INFO:top2vec:Finding topics\n"
          ]
        }
      ],
      "source": [
        "# using an embedding model (the only one we can use in our case as the other two avaible model are integrated with foreign languages\n",
        "model_train = Top2Vec(train.to_numpy(), embedding_model='universal-sentence-encoder')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_train.get_num_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH6ec7FnN8PL",
        "outputId": "5f500b9c-ef3b-4919-f956-a9f576efc1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words, word_scores, topic_nums = model_train.get_topics(2)\n",
        "topic_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJkGnx4H_3uy",
        "outputId": "8140a790-3278-4de6-935a-253a8ed1b124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['subplot', 'novel', 'trope', 'intrigue', 'erotica',\n",
              "        'predictable', 'scalzi', 'povs', 'cliche', 'novella',\n",
              "        'worldbuilding', 'protagonist', 'prose', 'storytelling',\n",
              "        'suspense', 'plot', 'blurb', 'goodreads', 'romance', 'austen',\n",
              "        'quirky', 'gritty', 'literary', 'frustrate', 'tedious', 'climax',\n",
              "        'writing', 'suspenseful', 'character', 'intriguing', 'genre',\n",
              "        'pacing', 'storyline', 'book', 'shallow', 'whiny', 'horror',\n",
              "        'prologue', 'retelling', 'write', 'gaiman', 'compelling',\n",
              "        'heroine', 'trilogy', 'boring', 'dialogue', 'narration',\n",
              "        'likable', 'angst', 'likeable'],\n",
              "       ['nonfiction', 'subplot', 'novel', 'narrative', 'storytelling',\n",
              "        'narration', 'trope', 'dystopian', 'worldbuilding', 'dramatic',\n",
              "        'fiction', 'protagonist', 'conflict', 'scalzi', 'intrigue',\n",
              "        'prejudice', 'tragedy', 'postapocalyptic', 'novella', 'dystopia',\n",
              "        'horror', 'literary', 'wwii', 'hero', 'angst', 'povs', 'war',\n",
              "        'depressing', 'compelling', 'plot', 'tragic', 'betray',\n",
              "        'predictable', 'memoir', 'austen', 'literature', 'dialogue',\n",
              "        'storyline', 'tale', 'drama', 'engaging', 'horrific',\n",
              "        'historical', 'paced', 'fictional', 'relatable', 'history',\n",
              "        'suspenseful', 'crash', 'cliche']], dtype='<U15')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_topics_words(mod,lista, num_word):\n",
        "  l = []\n",
        "  for i in range(len(lista)):\n",
        "    # the function model.similar_words returns both the words and the words scores, so we take only the first output\n",
        "    l += [wo for wo in [w for w in mod.similar_words(keywords=[lista[i]],num_words=num_word)[0] if w not in l]]\n",
        "  return l"
      ],
      "metadata": {
        "id": "4flYxzR3Upam"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list containing the 200 words similar for each genre (withouth duplicates)\n",
        "train_words_sim2 = create_topics_words(model_train, ['Art','Romance','Reality','Science','Mystery','Fiction'], 200)"
      ],
      "metadata": {
        "id": "8JLusXTVY4tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list containing the 500 words similar for each genre (withouth duplicates)\n",
        "train_words_sim5 = create_topics_words(model_train, ['Art','Romance','Reality','Science','Mystery','Fiction'], 500)"
      ],
      "metadata": {
        "id": "Xw-2dKn1ZpEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maintain_some_words(x, l):\n",
        "  lists = [word for word in x if word in l]\n",
        "  return lists"
      ],
      "metadata": {
        "id": "Q-urPmuVEsWU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['lemmatized_text'] = train_df['lemmatized_text'].apply(lambda x: ast.literal_eval(x))\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Zq0gTezXFQiD",
        "outputId": "6f98e5c6-5d43-4456-f07a-fb854d6d4ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_text genre  rating   book_id  \\\n",
              "0  breezy hijinks, fun to read. think i finished ...   Art       3  22718721   \n",
              "1  for the story, for the artwork. you know how t...   Art       2  13533744   \n",
              "2  rat queens so the rat queens are to fight the ...   Art       3  23012877   \n",
              "3  i knew nothing about eternals before reading t...   Art       2     47694   \n",
              "4  better than the last book, this one moves the ...   Art       3  12137592   \n",
              "\n",
              "                                     lemmatized_text  \\\n",
              "0  [breezy, hijinks, fun, read, think, finish, si...   \n",
              "1  [story, artwork, know, best, best, come, later...   \n",
              "2  [rat, queen, rat, queen, fight, man, kidnap, b...   \n",
              "3  [know, eternals, read, pretty, get, neil, gaim...   \n",
              "4  [good, book, move, plot, forward, ntroduces, d...   \n",
              "\n",
              "                                   lemmatized_joined  \n",
              "0  breezy hijinks fun read think finish sitting a...  \n",
              "1  story artwork know best best come later rejuve...  \n",
              "2  rat queen rat queen fight man kidnap bernardet...  \n",
              "3  know eternals read pretty get neil gaiman know...  \n",
              "4  good book move plot forward ntroduces dead pre...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-508bf00e-99e4-4509-8c6b-ef6b55bddc89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>genre</th>\n",
              "      <th>rating</th>\n",
              "      <th>book_id</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>lemmatized_joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breezy hijinks, fun to read. think i finished ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>22718721</td>\n",
              "      <td>[breezy, hijinks, fun, read, think, finish, si...</td>\n",
              "      <td>breezy hijinks fun read think finish sitting a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>for the story, for the artwork. you know how t...</td>\n",
              "      <td>Art</td>\n",
              "      <td>2</td>\n",
              "      <td>13533744</td>\n",
              "      <td>[story, artwork, know, best, best, come, later...</td>\n",
              "      <td>story artwork know best best come later rejuve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rat queens so the rat queens are to fight the ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>23012877</td>\n",
              "      <td>[rat, queen, rat, queen, fight, man, kidnap, b...</td>\n",
              "      <td>rat queen rat queen fight man kidnap bernardet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i knew nothing about eternals before reading t...</td>\n",
              "      <td>Art</td>\n",
              "      <td>2</td>\n",
              "      <td>47694</td>\n",
              "      <td>[know, eternals, read, pretty, get, neil, gaim...</td>\n",
              "      <td>know eternals read pretty get neil gaiman know...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>better than the last book, this one moves the ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>12137592</td>\n",
              "      <td>[good, book, move, plot, forward, ntroduces, d...</td>\n",
              "      <td>good book move plot forward ntroduces dead pre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-508bf00e-99e4-4509-8c6b-ef6b55bddc89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-508bf00e-99e4-4509-8c6b-ef6b55bddc89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-508bf00e-99e4-4509-8c6b-ef6b55bddc89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we analyze the case where we take only the 200 similar words for each genre, then for each record, from the lemmatized_text column, we check if each word is in the similar words list and, if so, we add it in the new \"topic_words\" column."
      ],
      "metadata": {
        "id": "9AhSPpLdb8cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['topic_words'] = train_df['lemmatized_text'].apply(lambda x: maintain_some_words(x,train_words_sim2))"
      ],
      "metadata": {
        "id": "YUD5GH-PFAiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "SKgYwCOVaOhv",
        "outputId": "8ab21f4a-0fcb-41b5-a532-65069e1355ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_text genre  rating   book_id  \\\n",
              "0  breezy hijinks, fun to read. think i finished ...   Art       3  22718721   \n",
              "1  for the story, for the artwork. you know how t...   Art       2  13533744   \n",
              "2  rat queens so the rat queens are to fight the ...   Art       3  23012877   \n",
              "3  i knew nothing about eternals before reading t...   Art       2     47694   \n",
              "4  better than the last book, this one moves the ...   Art       3  12137592   \n",
              "\n",
              "                                     lemmatized_text  \\\n",
              "0  [breezy, hijinks, fun, read, think, finish, si...   \n",
              "1  [story, artwork, know, best, best, come, later...   \n",
              "2  [rat, queen, rat, queen, fight, man, kidnap, b...   \n",
              "3  [know, eternals, read, pretty, get, neil, gaim...   \n",
              "4  [good, book, move, plot, forward, ntroduces, d...   \n",
              "\n",
              "                                   lemmatized_joined  \\\n",
              "0  breezy hijinks fun read think finish sitting a...   \n",
              "1  story artwork know best best come later rejuve...   \n",
              "2  rat queen rat queen fight man kidnap bernardet...   \n",
              "3  know eternals read pretty get neil gaiman know...   \n",
              "4  good book move plot forward ntroduces dead pre...   \n",
              "\n",
              "                                         topic_words  \\\n",
              "0  [fun, author, feel, shit, gender, piece, woman...   \n",
              "1  [story, artwork, know, new, comic, amazing, su...   \n",
              "2  [man, draw, artist, artist, mature, lady, kind...   \n",
              "3  [know, gaiman, know, series, know, character, ...   \n",
              "4  [book, plot, dead, government, interesting, th...   \n",
              "\n",
              "                                       topic_words_2  \n",
              "0  [fun, author, feel, shit, gender, piece, woman...  \n",
              "1  [story, artwork, know, new, comic, amazing, su...  \n",
              "2  [man, draw, artist, artist, mature, lady, kind...  \n",
              "3  [know, gaiman, know, series, know, character, ...  \n",
              "4  [book, plot, dead, government, interesting, th...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15314a12-7e68-4c97-9418-585753738427\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>genre</th>\n",
              "      <th>rating</th>\n",
              "      <th>book_id</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>lemmatized_joined</th>\n",
              "      <th>topic_words</th>\n",
              "      <th>topic_words_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>breezy hijinks, fun to read. think i finished ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>22718721</td>\n",
              "      <td>[breezy, hijinks, fun, read, think, finish, si...</td>\n",
              "      <td>breezy hijinks fun read think finish sitting a...</td>\n",
              "      <td>[fun, author, feel, shit, gender, piece, woman...</td>\n",
              "      <td>[fun, author, feel, shit, gender, piece, woman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>for the story, for the artwork. you know how t...</td>\n",
              "      <td>Art</td>\n",
              "      <td>2</td>\n",
              "      <td>13533744</td>\n",
              "      <td>[story, artwork, know, best, best, come, later...</td>\n",
              "      <td>story artwork know best best come later rejuve...</td>\n",
              "      <td>[story, artwork, know, new, comic, amazing, su...</td>\n",
              "      <td>[story, artwork, know, new, comic, amazing, su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rat queens so the rat queens are to fight the ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>23012877</td>\n",
              "      <td>[rat, queen, rat, queen, fight, man, kidnap, b...</td>\n",
              "      <td>rat queen rat queen fight man kidnap bernardet...</td>\n",
              "      <td>[man, draw, artist, artist, mature, lady, kind...</td>\n",
              "      <td>[man, draw, artist, artist, mature, lady, kind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i knew nothing about eternals before reading t...</td>\n",
              "      <td>Art</td>\n",
              "      <td>2</td>\n",
              "      <td>47694</td>\n",
              "      <td>[know, eternals, read, pretty, get, neil, gaim...</td>\n",
              "      <td>know eternals read pretty get neil gaiman know...</td>\n",
              "      <td>[know, gaiman, know, series, know, character, ...</td>\n",
              "      <td>[know, gaiman, know, series, know, character, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>better than the last book, this one moves the ...</td>\n",
              "      <td>Art</td>\n",
              "      <td>3</td>\n",
              "      <td>12137592</td>\n",
              "      <td>[good, book, move, plot, forward, ntroduces, d...</td>\n",
              "      <td>good book move plot forward ntroduces dead pre...</td>\n",
              "      <td>[book, plot, dead, government, interesting, th...</td>\n",
              "      <td>[book, plot, dead, government, interesting, th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15314a12-7e68-4c97-9418-585753738427')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15314a12-7e68-4c97-9418-585753738427 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15314a12-7e68-4c97-9418-585753738427');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newtrain = train_df['topic_words'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "LgOiJBCfYh6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CountVectorizer**"
      ],
      "metadata": {
        "id": "dPiHuHUEirhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=2, max_features=20000)\n",
        "word_doc_matrix = vectorizer.fit_transform(newtrain)"
      ],
      "metadata": {
        "id": "khnThRuRaKLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(word_doc_matrix,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "5KnvIDU4acYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=4.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Yval)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2172b2-2008-401c-e8a7-824e7f4557a5",
        "id": "lUUdpyhFvtIG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=4.0, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy Score ->  55.166666666666664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By selecting 200 similar words** for each genre and using them for classification, **SVM accuracy increases to 58%**, using CountVectorizer alone. **Using instead 500 similar words** for each genre, the **SVM accuracy reaches 61%** as shown below."
      ],
      "metadata": {
        "id": "yT4IVmBfbFiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['topic_words_2'] = train_df['lemmatized_text'].apply(lambda x: maintain_some_words(x,train_words_sim5))"
      ],
      "metadata": {
        "id": "2fqptMYuc-n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newtrain2 = train_df['topic_words_2'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "aFEqs-Tbc-n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=2, max_features=20000)\n",
        "word_doc_matrix = vectorizer.fit_transform(newtrain2)"
      ],
      "metadata": {
        "id": "xvhCSQDEc-n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(word_doc_matrix,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "xn61UI2lgx6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see performance on validation \n",
        "model_naive = MultinomialNB(alpha=0.2)\n",
        "model_naive.fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a90ee06-aee3-46c4-abc7-9481b9ec6809",
        "id": "PosmT08Uflq8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_naive.predict(Xtrain)\n",
        "y_pred = model_naive.predict(Xval)\n",
        "# comparing real values with predicted values  \n",
        "print(\"Train accuracy for Naive (in %): {}\".format(metrics.accuracy_score(Ytrain, y_train_pred)*100))\n",
        "print(\"Validation accuracy for Naive (in %): {}\".format(metrics.accuracy_score(Yval, y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6329ba15-9380-4381-c2f5-5cd64bf77378",
        "id": "IW5j_6zHflq9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy for Naive (in %): 71.91666666666666\n",
            "Validation accuracy for Naive (in %): 63.66666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=5.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ----> {}\".format(accuracy_score(predictions_SVM, Yval)*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259a4e5d-2563-4c0d-9874-8c520fbed54d",
        "id": "HibE_Rtchvq2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=5.0, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score ----> 60.77777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Countvectorizer + Umap**"
      ],
      "metadata": {
        "id": "bR8-4Mo1ehed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = umap_reduction(word_doc_matrix)"
      ],
      "metadata": {
        "id": "7e62ChG5al-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(embedding,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "e-olZQxjekzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ----> {}\".format(accuracy_score(predictions_SVM, Yval)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9c5e18-7082-4a64-b437-e2cc2eed5f54",
        "id": "nS07UHWNes4z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score ----> 31.472222222222225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compared to previous results, even if we use a umap reduction the perfomance does not improve so much."
      ],
      "metadata": {
        "id": "ytZIlr0GgIGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = umap_reduction(word_doc_matrix,6)"
      ],
      "metadata": {
        "id": "u-E0fqqmfqvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(embedding,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "lRP-XoKjfuFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ----> {}\".format(accuracy_score(predictions_SVM, Yval)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d30779-0a28-436f-ae32-1235732ebd0c",
        "id": "295nHz8ifuFV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score ----> 43.666666666666664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tf-idf** "
      ],
      "metadata": {
        "id": "Q-0FM30gj4RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=20000)\n",
        "TrainTDF = Tfidf_vect.fit_transform(newtrain2)"
      ],
      "metadata": {
        "id": "MslVbjaHkaid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(TrainTDF,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "xdri384WktZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e042f3eb-97ea-4f58-e0ed-a8f7e2753fe2",
        "id": "yK0tUONDktZ_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score ---> 23.194444444444446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see performance on validation \n",
        "model_naive = MultinomialNB(alpha=0.2)\n",
        "model_naive.fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea41932-c372-4e17-f9cf-39df22a44520",
        "id": "TjuwpNPsjmiu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_naive.predict(Xtrain)\n",
        "y_pred = model_naive.predict(Xval)\n",
        "# comparing real values with predicted values  \n",
        "print(\"Train accuracy(in %): {}\".format(metrics.accuracy_score(Ytrain, y_train_pred)*100))\n",
        "print(\"Validation accuracy(in %): {}\".format(metrics.accuracy_score(Yval, y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db342281-4aaf-4c72-afb1-f20480cfc816",
        "id": "QGL8aYXiktaA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy(in %): 72.86904761904762\n",
            "Validation accuracy(in %): 62.38888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tf-idf + Umap**"
      ],
      "metadata": {
        "id": "lsfJ4o4tqki0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = umap_reduction(TrainTDF,6)"
      ],
      "metadata": {
        "id": "5eK4SxF3pCXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test datasets\n",
        "Xtrain, Xval, Ytrain, Yval = train_test_split(embedding,Yt,test_size=0.3)"
      ],
      "metadata": {
        "id": "p_SslQHjpCXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=3.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(Xtrain,Ytrain)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Xval)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"\\nSVM Accuracy Score ---> {}\".format(accuracy_score(predictions_SVM, Yval)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644f8547-2123-40a9-e7d3-560ef402f614",
        "id": "dZBRzEvnpIC9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=3.0, gamma='auto')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Accuracy Score ---> 45.80555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test set**"
      ],
      "metadata": {
        "id": "1bcXeDgJZoUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the perfomance of **test set**, in this case we choose only the models that give us better results: *Naive Bayes Classifier* and *SVM*. The test set score for Naive Bayes, taking into account only the Tf-idf case, is not so good as we expected:"
      ],
      "metadata": {
        "id": "APcdxlPzkj5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=20000)\n",
        "TrainTDF = Tfidf_vect.fit_transform(train)\n",
        "TestTDF = Tfidf_vect.fit_transform(test)"
      ],
      "metadata": {
        "id": "x3-1ixBNkIvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see performance on validation \n",
        "model_naive = MultinomialNB(alpha=0.2)\n",
        "model_naive.fit(TrainTDF, Yt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a956055-f347-4c1b-9c91-81f0ed5c16f6",
        "id": "Uxsvq-szkIvT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_naive.predict(TrainTDF)\n",
        "y_pred = model_naive.predict(TestTDF)\n",
        "  \n",
        "# comparing real values with predicted values  \n",
        "print(\"Train accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Yt, y_train_pred)*100))\n",
        "print(\"Test accuracy for Naive Bayes (in %): {}\".format(metrics.accuracy_score(Ytest, y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce601a3c-cfb8-4de6-f671-d4507e0b6656",
        "id": "7lnygOgWkIvT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy for Naive Bayes (in %): 93.60833333333333\n",
            "Validation accuracy for Naive Bayes (in %): 20.718992767211358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For *SVM*, using CountVectorizer + Umap and as input the filtered column with Top2Vec, we obtained the following score:"
      ],
      "metadata": {
        "id": "acMtGKFsk0Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_test = Top2Vec(test.to_numpy(), embedding_model='universal-sentence-encoder')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMGEByUclLe7",
        "outputId": "b3353781-19af-4c11-ef2a-35ba1af9167a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-08 01:46:15,763 - top2vec - INFO - Pre-processing documents for training\n",
            "INFO:top2vec:Pre-processing documents for training\n",
            "2022-12-08 01:46:28,645 - top2vec - INFO - Downloading universal-sentence-encoder model\n",
            "INFO:top2vec:Downloading universal-sentence-encoder model\n",
            "2022-12-08 01:46:33,141 - top2vec - INFO - Creating joint document/word embedding\n",
            "INFO:top2vec:Creating joint document/word embedding\n",
            "2022-12-08 01:47:09,869 - top2vec - INFO - Creating lower dimension embedding of documents\n",
            "INFO:top2vec:Creating lower dimension embedding of documents\n",
            "2022-12-08 01:47:57,765 - top2vec - INFO - Finding dense areas of documents\n",
            "INFO:top2vec:Finding dense areas of documents\n",
            "2022-12-08 01:48:05,647 - top2vec - INFO - Finding topics\n",
            "INFO:top2vec:Finding topics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['lemmatized_text'] = test_df['lemmatized_text'].apply(lambda x: ast.literal_eval(x))\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "16a93f33-c797-44f9-e1cd-27feaf05ae99",
        "id": "A_e_CHdJIX6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         book_id                                        review_text    genre  \\\n",
              "228469  13642963  flavia de luce mystery series eleven year old ...  Mystery   \n",
              "10994      16433  i've read four or five odd thomas books thus f...  Mystery   \n",
              "127447  22669832  i read the first of this book when i finally d...  Romance   \n",
              "47935   16068910  firstly, thanks to harperteen for this earc. r...  Fiction   \n",
              "162043  22457959  the series tear asunder is one that i have rea...  Mystery   \n",
              "\n",
              "                                          lemmatized_text  \\\n",
              "228469  [flavia, luce, mystery, series, eleven, year, ...   \n",
              "10994   ['ve, read, four, five, odd, thomas, book, thu...   \n",
              "127447  [read, the, first, this, book, when, finally, ...   \n",
              "47935   [firstly, thanks, harperteen, for, this, earc,...   \n",
              "162043  [the, series, tear, asunder, one, that, have, ...   \n",
              "\n",
              "                                        lemmatized_joined  \n",
              "228469  flavia luce mystery series eleven year old fla...  \n",
              "10994   've read four five odd thomas book thus far an...  \n",
              "127447  read the first this book when finally decide t...  \n",
              "47935   firstly thanks harperteen for this earc review...  \n",
              "162043  the series tear asunder one that have really e...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b2a1e7b-36e2-433e-beb5-e034357a8f10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>genre</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>lemmatized_joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>228469</th>\n",
              "      <td>13642963</td>\n",
              "      <td>flavia de luce mystery series eleven year old ...</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>[flavia, luce, mystery, series, eleven, year, ...</td>\n",
              "      <td>flavia luce mystery series eleven year old fla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10994</th>\n",
              "      <td>16433</td>\n",
              "      <td>i've read four or five odd thomas books thus f...</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>['ve, read, four, five, odd, thomas, book, thu...</td>\n",
              "      <td>'ve read four five odd thomas book thus far an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127447</th>\n",
              "      <td>22669832</td>\n",
              "      <td>i read the first of this book when i finally d...</td>\n",
              "      <td>Romance</td>\n",
              "      <td>[read, the, first, this, book, when, finally, ...</td>\n",
              "      <td>read the first this book when finally decide t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47935</th>\n",
              "      <td>16068910</td>\n",
              "      <td>firstly, thanks to harperteen for this earc. r...</td>\n",
              "      <td>Fiction</td>\n",
              "      <td>[firstly, thanks, harperteen, for, this, earc,...</td>\n",
              "      <td>firstly thanks harperteen for this earc review...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162043</th>\n",
              "      <td>22457959</td>\n",
              "      <td>the series tear asunder is one that i have rea...</td>\n",
              "      <td>Mystery</td>\n",
              "      <td>[the, series, tear, asunder, one, that, have, ...</td>\n",
              "      <td>the series tear asunder one that have really e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b2a1e7b-36e2-433e-beb5-e034357a8f10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b2a1e7b-36e2-433e-beb5-e034357a8f10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b2a1e7b-36e2-433e-beb5-e034357a8f10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list containing the 500 words similar for each genre (withouth duplicates)\n",
        "train_words_sim5 = create_topics_words(model_train, ['Art','Romance','Reality','Science','Mystery','Fiction'], 500)\n",
        "test_words_sim5 = create_topics_words(model_test, ['Art','Romance','Reality','Science','Mystery','Fiction'], 1000)"
      ],
      "metadata": {
        "id": "MRPm3ezIlHaO"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['topic_words'] = test_df['lemmatized_text'].apply(lambda x: maintain_some_words(x,test_words_sim5))"
      ],
      "metadata": {
        "id": "yj5tqPE3Iiad"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newtest = test_df['topic_words'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "d_31y4IDIuG4"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=2, max_features=20000)\n",
        "word_doc_matrix = vectorizer.fit_transform(newtrain2)\n",
        "word_doc_matrix_test = vectorizer.fit_transform(newtest)"
      ],
      "metadata": {
        "id": "A_Yno2yXJQcy"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = umap_reduction(word_doc_matrix)\n",
        "embedding_t = umap_reduction(word_doc_matrix_test)"
      ],
      "metadata": {
        "id": "IHzY4mqQM4gY"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=2.0, kernel='rbf', degree=3, gamma='auto')\n",
        "SVM.fit(embedding,Yt)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(embedding_t)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> {}\".format(accuracy_score(predictions_SVM, Ytest)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb615a68-d4e1-4385-f6f0-4a59a0a583d1",
        "id": "L5AC3_u4JQcz"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy Score ->  55.04420037503348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusions**"
      ],
      "metadata": {
        "id": "hZxumNCxgmVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, the best results we get are the following:\n",
        "\n",
        "*   For **Naive Bayes**, using only CountVectorizer or Tf-Idf, we get roughly a **94% of accuracy in training set and 73% in validation set**.\n",
        "*   For **SVM**, the best case is obtained with the new column reduced with the most semantically most similar words and using CountVectorizer (reaching a **61% of validation accuracy**). But, in general, in the previous cases it was possible to see a good improvement in accuracy using the Umap Reduction, in particular with a reduction of 6 components (even for 2 components but not so much compared to the latter.\n",
        "*   For **LSTM**, we didn't find a lower validation loss and, using a Patience parameter, decided to stop using a 3/5 value of Patience. In the analyzed cases, the best case is obtained with CountVectorizer + Umap (**40%**).\n",
        "*  For Test Set, we took only the models in which we obtained a higher validation accuracy, but obtaining lower scores. "
      ],
      "metadata": {
        "id": "P08RWVLNhXIG"
      }
    }
  ]
}